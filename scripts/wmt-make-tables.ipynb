{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77c962c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import regex as re\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ebe637c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gpt-3', 'en', 'fr', 'source+target', 'gpt-3-en-fr-source+target']\n"
     ]
    }
   ],
   "source": [
    "# Parse the template to extract: \n",
    "# - the instruction /prompt, \n",
    "# - the source\n",
    "# - the target\n",
    "# - the type (only target, or source and target)\n",
    "# also returns a \"normalized\" version of the prompt\n",
    "def parse_wmt_template(template):\n",
    "    # print(template)\n",
    "    if (template == \"gpt3-fr-en\" or template == \"gpt3-en-fr\"):\n",
    "        template = template + \"-target\"\n",
    "    template = re.sub(\"gpt\\-3\", \"gpt3\", template)\n",
    "    template = re.sub(\"translate\\_as\\_\", \"translate_as-\", template)\n",
    "    template = re.sub(\"source\\-target\", \"source+target\", template)\n",
    "    [prompt, src, trg, prptype] = template.split(\"-\")\n",
    "    \n",
    "    template = re.sub(\"gpt3\", \"gpt-3\", template)\n",
    "    prompt   = re.sub(\"gpt3\", \"gpt-3\", prompt)   \n",
    "    return([prompt, src, trg, prptype, template])\n",
    "\n",
    "print(parse_wmt_template(\"gpt-3-en-fr-source+target\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0144dcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize post processing procedure, adding 'none' when none is used\n",
    "def parse_wmt_postproc(postproc):\n",
    "    p = re.sub('^[0-9]+\\.?', '', str(postproc))\n",
    "    if (p == \"\" or p == \"nan\" or p == \"NaN\"):\n",
    "        p = \"none\"\n",
    "    return(p)\n",
    "\n",
    "# normalize model names\n",
    "def parse_wmt_model(model):\n",
    "    if (model == \"bloom-6b3\"):\n",
    "        model = \"bloom-7b1\"\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d22c414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object Path.glob at 0x7fc9b11143d0>\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path \n",
    "def collect_results(path=None, task = \"*\", metric = \"bleu\", shot=\"*\"):\n",
    "    \"\"\"\n",
    "    Collect results from all datasets as csv files\n",
    "    \"\"\"\n",
    "    dfslst = []\n",
    "    root_dir = Path(path)\n",
    "    # files = source_dir.iterdir()\n",
    "    pattern = task + \"/\" + shot + \"/\" + \"*\" + metric + \"*.tsv\"\n",
    "    # print(pattern)\n",
    "    files = root_dir.glob(pattern)\n",
    "    # files = root_dir.glob('*/*/*bleu*.tsv')\n",
    "    print(files)\n",
    "    for file in files:\n",
    "        # print(file.name)       \n",
    "        dfslst.append(pd.read_csv(file, \n",
    "                                  sep=\"\\t\", \n",
    "                                  header=0, \n",
    "                                  dtype = {'model':str,'task':str,'template':str,'fewshot':int,'seed':int,'postproc':str,'timestamp':str,'filename':str,'BLEU':float},\n",
    "                                  index_col=False))   \n",
    "    allres = pd.concat(dfslst)\n",
    "    post = allres['postproc'].apply(parse_wmt_postproc)\n",
    "    allres['postproc'] = post\n",
    "    prompt = allres['template'].apply(parse_wmt_template)\n",
    "    # newdf = pd.DataFrame([c[0] for c in xa], [c[1] for c in xa], [c[2] for c in xa],[c[3] for c in xa])\n",
    "    # newdf = pd.DataFrame({\"name\":[c[0] for c in xa],\"src\":[c[1] for c in xa], \"trg\":[c[2] for c in xa], \"type\":[c[3] for c in xa]})\n",
    "    for (cname, cindex) in [(\"prompt\", 0), (\"src\", 1), (\"trg\", 2), (\"prptype\", 3), (\"template\", 4)]:\n",
    "        allres[cname] = [c[cindex] for c in prompt.values]\n",
    "    return(allres)\n",
    "    # df.assign(newdf)\n",
    "\n",
    "rootdir  = \"/Users/yvon/dat/Projects/2021-BigScience/mt-bigscience/outputs/\"\n",
    "allres   = collect_results(rootdir, task=\"wmt14*\", metric=\"bleu\")\n",
    "\n",
    "# allcomet = collect_results(rootdir, task=\"wmt14*\", metric=\"comet\")\n",
    "allres.to_csv(\"/Users/yvon/Downloads/allres.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe7468b",
   "metadata": {},
   "source": [
    "## Main table for the BLOOM paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3f72fa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    model  fewshot                                template   BLEU src trg\n",
      "16  bloom        0  a_good_translation-en-fr-source+target  15.38  en  fr\n",
      "24  bloom        1  a_good_translation-en-fr-source+target  36.39  en  fr\n",
      "0   bloom        0  a_good_translation-en-hi-source+target   1.90  en  hi\n",
      "8   bloom        1  a_good_translation-en-hi-source+target  14.49  en  hi\n",
      "17  bloom        0  a_good_translation-fr-en-source+target  14.15  fr  en\n",
      "25  bloom        1  a_good_translation-fr-en-source+target  36.56  fr  en\n",
      "1   bloom        0  a_good_translation-hi-en-source+target  10.19  hi  en\n",
      "9   bloom        1  a_good_translation-hi-en-source+target  24.60  hi  en\n",
      "18  bloom        0                      gpt-3-en-fr-target   7.90  en  fr\n",
      "26  bloom        1                      gpt-3-en-fr-target  32.55  en  fr\n",
      "2   bloom        0                      gpt-3-en-hi-target   0.26  en  hi\n",
      "10  bloom        1                      gpt-3-en-hi-target   6.51  en  hi\n",
      "19  bloom        0                      gpt-3-fr-en-target  12.73  fr  en\n",
      "27  bloom        1                      gpt-3-fr-en-target  33.14  fr  en\n",
      "3   bloom        0                      gpt-3-hi-en-target   0.66  hi  en\n",
      "11  bloom        1                      gpt-3-hi-en-target   9.98  hi  en\n",
      "20  bloom        0                    version-en-fr-target  21.96  en  fr\n",
      "28  bloom        1                    version-en-fr-target  34.22  en  fr\n",
      "4   bloom        0                    version-en-hi-target   1.96  en  hi\n",
      "12  bloom        1                    version-en-hi-target  13.95  en  hi\n",
      "21  bloom        0                    version-fr-en-target  26.79  fr  en\n",
      "29  bloom        1                    version-fr-en-target  35.42  fr  en\n",
      "5   bloom        0                    version-hi-en-target  11.48  hi  en\n",
      "13  bloom        1                    version-hi-en-target  25.80  hi  en\n",
      "22  bloom        0                xglm-en-fr-source+target  14.91  en  fr\n",
      "30  bloom        1                xglm-en-fr-source+target  27.83  en  fr\n",
      "6   bloom        0                xglm-en-hi-source+target   6.80  en  hi\n",
      "14  bloom        1                xglm-en-hi-source+target  13.62  en  hi\n",
      "23  bloom        0                xglm-fr-en-source+target  15.52  fr  en\n",
      "31  bloom        1                xglm-fr-en-source+target  34.61  fr  en\n",
      "7   bloom        0                xglm-hi-en-source+target  12.05  hi  en\n",
      "15  bloom        1                xglm-hi-en-source+target  25.04  hi  en\n"
     ]
    }
   ],
   "source": [
    "templateList = [\n",
    "    \"a_good_translation-fr-en-source+target\", \"a_good_translation-en-fr-source+target\", \\\n",
    "    \"gpt-3-en-fr-target\", \"gpt-3-fr-en-target\", \\\n",
    "    \"version-en-fr-target\", \"version-fr-en-target\", \\\n",
    "    \"xglm-en-fr-source+target\", \"xglm-fr-en-source+target\", \\\n",
    "    \"a_good_translation-en-hi-source+target\", \"a_good_translation-hi-en-source+target\", \n",
    "    \"gpt-3-en-hi-target\", \"gpt-3-hi-en-target\", \\\n",
    "    \"version-en-hi-target\", \"version-hi-en-target\", \\\n",
    "    \"xglm-en-hi-source+target\", \"xglm-hi-en-source+target\"\n",
    "    ] \n",
    "\n",
    "mask = pd.array(allres['fewshot'] < 2, dtype=\"boolean\") & \\\n",
    "pd.array(allres['postproc'] == \"none\", dtype =\"boolean\") & \\\n",
    "pd.array(allres['model'] == \"bloom\", dtype=\"boolean\") &\\\n",
    "pd.array(allres['template'].isin(templateList))\n",
    "filtered = allres[mask]\n",
    "selected = filtered.loc[:, ['model', 'fewshot', 'template', 'BLEU', 'src', 'trg',]]\n",
    "selected.drop_duplicates(keep='first', inplace=True, ignore_index=True)\n",
    "print(selected.sort_values(by=['template','fewshot', 'src', 'trg'], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650e5831",
   "metadata": {},
   "source": [
    "## Main table for (Bawden and Yvon) ##\n",
    "The first table is about getting all the results we have for one prompt (xglm source target), all languages pairs, in two versions. The models considered are:\n",
    "- bloom\n",
    "- t0\n",
    "- opt\n",
    "- T0pp\n",
    "\n",
    "Caveat: currently we just compute and print the numbers, but do not produce the tex table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65b197d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    model  fewshot                     postproc   BLEU src trg\n",
      "24  bloom        0  newline-cut-custom-truncate  32.25  en  fr\n",
      "25  bloom        0                         none  14.91  en  fr\n",
      "28    opt        0  newline-cut-custom-truncate  18.86  en  fr\n",
      "29    opt        0                         none  12.95  en  fr\n",
      "32     t0        0  newline-cut-custom-truncate   1.21  en  fr\n",
      "33     t0        0                         none   1.21  en  fr\n",
      "0   bloom        0  newline-cut-custom-truncate  12.10  en  hi\n",
      "1   bloom        0                         none   6.80  en  hi\n",
      "4     opt        0  newline-cut-custom-truncate   0.11  en  hi\n",
      "5     opt        0                         none   0.14  en  hi\n",
      "8      t0        0  newline-cut-custom-truncate   0.16  en  hi\n",
      "9      t0        0                         none   0.16  en  hi\n",
      "26  bloom        0  newline-cut-custom-truncate  37.16  fr  en\n",
      "27  bloom        0                         none  15.52  fr  en\n",
      "30    opt        0  newline-cut-custom-truncate  33.18  fr  en\n",
      "31    opt        0                         none  15.54  fr  en\n",
      "34     t0        0  newline-cut-custom-truncate  25.80  fr  en\n",
      "35     t0        0                         none  25.79  fr  en\n",
      "2   bloom        0  newline-cut-custom-truncate  24.29  hi  en\n",
      "3   bloom        0                         none  12.05  hi  en\n",
      "6     opt        0  newline-cut-custom-truncate   0.51  hi  en\n",
      "7     opt        0                         none   0.42  hi  en\n",
      "10     t0        0  newline-cut-custom-truncate   0.00  hi  en\n",
      "11     t0        0                         none   0.00  hi  en\n",
      "36  bloom        1  newline-cut-custom-truncate  36.29  en  fr\n",
      "37  bloom        1                         none  27.83  en  fr\n",
      "40    opt        1  newline-cut-custom-truncate  22.31  en  fr\n",
      "41    opt        1                         none  21.92  en  fr\n",
      "44     t0        1  newline-cut-custom-truncate   1.41  en  fr\n",
      "45     t0        1                         none   1.41  en  fr\n",
      "12  bloom        1  newline-cut-custom-truncate  15.73  en  hi\n",
      "13  bloom        1                         none  13.62  en  hi\n",
      "16    opt        1  newline-cut-custom-truncate   0.08  en  hi\n",
      "17    opt        1                         none   0.08  en  hi\n",
      "20     t0        1  newline-cut-custom-truncate   0.12  en  hi\n",
      "21     t0        1                         none   0.12  en  hi\n",
      "38  bloom        1  newline-cut-custom-truncate  38.18  fr  en\n",
      "39  bloom        1                         none  34.61  fr  en\n",
      "42    opt        1  newline-cut-custom-truncate  33.25  fr  en\n",
      "43    opt        1                         none  24.55  fr  en\n",
      "46     t0        1  newline-cut-custom-truncate  21.07  fr  en\n",
      "47     t0        1                         none  21.01  fr  en\n",
      "14  bloom        1  newline-cut-custom-truncate  25.04  hi  en\n",
      "15  bloom        1                         none  25.04  hi  en\n",
      "18    opt        1  newline-cut-custom-truncate   0.61  hi  en\n",
      "19    opt        1                         none   0.58  hi  en\n",
      "22     t0        1  newline-cut-custom-truncate   0.01  hi  en\n",
      "23     t0        1                         none   0.01  hi  en\n"
     ]
    }
   ],
   "source": [
    "mask = pd.array(allres['prompt'] == \"xglm\",dtype=\"boolean\") & \\\n",
    "    pd.array(allres['fewshot'] < 2, dtype=\"boolean\") & \\\n",
    "    pd.array(allres['postproc'] != \"newline-cut\") &\\\n",
    "    (pd.array(allres['model'] == \"bloom\",dtype=\"boolean\") |\n",
    "     pd.array(allres['model'] == \"t0\",dtype=\"boolean\") |\n",
    "     pd.array(allres['model'] == \"opt\", dtype=\"boolean\")) &\\\n",
    "    pd.array(allres['prptype'] == \"source+target\")\n",
    "filtered = allres[mask]\n",
    "selected = filtered.loc[:, ['model', 'fewshot', 'postproc', 'BLEU', 'src', 'trg',]]\n",
    "selected.drop_duplicates(keep='first', inplace=True, ignore_index=True)\n",
    "print(selected.sort_values(by=['fewshot', 'src', 'trg', 'model', 'postproc'], axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040df041",
   "metadata": {},
   "source": [
    "----\n",
    "### Analysis of languages occurring in the output translations ###\n",
    "This analysis relies on fast text, and is based on the same configurations as for the previous table: \n",
    "one prompt, all language pairs\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4fb134f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['en-hi', 'hi-en', 'en-fr', 'fr-en']\n",
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Output language identification results for en-hi (newline-cut-custom-truncate)}\n",
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "{} & \\multicolumn{2}{l}{0} & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{5} \\\\\n",
      "{} & \\multicolumn{2}{l}{ldiff} & \\multicolumn{2}{l}{ldiff} & \\multicolumn{2}{l}{ldiff} & \\multicolumn{2}{l}{ldiff} \\\\\n",
      "{} &  count &   mean &  count &  mean &  count &  mean &  count &  mean \\\\\n",
      "\\midrule\n",
      "ceb &    1.0 & -150.0 &    NaN &   NaN &    NaN &   NaN &    NaN &   NaN \\\\\n",
      "en  &  476.0 &   10.5 &   48.0 &  12.4 &   71.0 &  13.9 &   26.0 &  18.8 \\\\\n",
      "eo  &    1.0 & -134.0 &    NaN &   NaN &    NaN &   NaN &    NaN &   NaN \\\\\n",
      "fi  &    1.0 &   19.0 &    NaN &   NaN &    NaN &   NaN &    NaN &   NaN \\\\\n",
      "fr  &    2.0 &   94.5 &    NaN &   NaN &    NaN &   NaN &    NaN &   NaN \\\\\n",
      "gom &    2.0 &    6.5 &    1.0 &   4.0 &    NaN &   NaN &    1.0 &   0.0 \\\\\n",
      "hi  & 1998.0 &    9.3 & 2431.0 &   6.0 & 2403.0 &   5.5 & 2457.0 &   5.5 \\\\\n",
      "hsb &    1.0 &   98.0 &    NaN &   NaN &    NaN &   NaN &    NaN &   NaN \\\\\n",
      "ht  &    2.0 &  147.0 &    6.0 & 257.5 &   11.0 & 135.3 &    1.0 & 158.0 \\\\\n",
      "hu  &    1.0 &   71.0 &    NaN &   NaN &    NaN &   NaN &    NaN &   NaN \\\\\n",
      "lv  &    3.0 &   63.3 &    NaN &   NaN &    NaN &   NaN &    NaN &   NaN \\\\\n",
      "mr  &    5.0 &   64.4 &   11.0 &  14.6 &   17.0 &  11.7 &   19.0 &   6.0 \\\\\n",
      "ne  &    5.0 &    7.6 &    9.0 &  28.2 &    4.0 &  16.8 &    3.0 &   8.3 \\\\\n",
      "nl  &    2.0 &  -13.5 &    NaN &   NaN &    NaN &   NaN &    NaN &   NaN \\\\\n",
      "pt  &    1.0 &   24.0 &    NaN &   NaN &    NaN &   NaN &    NaN &   NaN \\\\\n",
      "sa  &    1.0 &  -25.0 &    NaN &   NaN &    NaN &   NaN &    NaN &   NaN \\\\\n",
      "sw  &    1.0 &   12.0 &    NaN &   NaN &    NaN &   NaN &    NaN &   NaN \\\\\n",
      "tl  &    1.0 &   24.0 &    NaN &   NaN &    NaN &   NaN &    NaN &   NaN \\\\\n",
      "war &    3.0 &    3.0 &    NaN &   NaN &    NaN &   NaN &    NaN &   NaN \\\\\n",
      "vec &    NaN &    NaN &    1.0 & -38.0 &    NaN &   NaN &    NaN &   NaN \\\\\n",
      "new &    NaN &    NaN &    NaN &   NaN &    1.0 &  25.0 &    NaN &   NaN \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Output language identification results for hi-en (newline-cut-custom-truncate)}\n",
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "{} & \\multicolumn{2}{l}{0} & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{5} \\\\\n",
      "{} & \\multicolumn{2}{l}{ldiff} & \\multicolumn{2}{l}{ldiff} & \\multicolumn{2}{l}{ldiff} & \\multicolumn{2}{l}{ldiff} \\\\\n",
      "{} &  count &  mean &  count &  mean &  count &  mean &  count &  mean \\\\\n",
      "\\midrule\n",
      "en  & 2469.0 &   4.0 & 2499.0 &   5.1 & 2503.0 &   3.8 & 2498.0 &   3.0 \\\\\n",
      "fr  &    1.0 & 151.0 &    1.0 &  -5.0 &    NaN &   NaN &    1.0 &   8.0 \\\\\n",
      "hi  &   29.0 &   3.3 &    2.0 &   0.0 &    NaN &   NaN &    NaN &   NaN \\\\\n",
      "ht  &    6.0 & 199.8 &    NaN &   NaN &    NaN &   NaN &    NaN &   NaN \\\\\n",
      "it  &    1.0 & 139.0 &    NaN &   NaN &    1.0 & -18.0 &    3.0 &   4.3 \\\\\n",
      "nl  &    1.0 &   9.0 &    NaN &   NaN &    NaN &   NaN &    2.0 &  -3.0 \\\\\n",
      "id  &    NaN &   NaN &    1.0 &  -6.0 &    NaN &   NaN &    NaN &   NaN \\\\\n",
      "nds &    NaN &   NaN &    1.0 &  16.0 &    NaN &   NaN &    NaN &   NaN \\\\\n",
      "pl  &    NaN &   NaN &    1.0 & -14.0 &    NaN &   NaN &    NaN &   NaN \\\\\n",
      "tr  &    NaN &   NaN &    1.0 & -15.0 &    NaN &   NaN &    NaN &   NaN \\\\\n",
      "war &    NaN &   NaN &    1.0 & 344.0 &    NaN &   NaN &    NaN &   NaN \\\\\n",
      "de  &    NaN &   NaN &    NaN &   NaN &    1.0 & -15.0 &    1.0 & 188.0 \\\\\n",
      "es  &    NaN &   NaN &    NaN &   NaN &    1.0 &   2.0 &    NaN &   NaN \\\\\n",
      "la  &    NaN &   NaN &    NaN &   NaN &    1.0 &  17.0 &    NaN &   NaN \\\\\n",
      "fi  &    NaN &   NaN &    NaN &   NaN &    NaN &   NaN &    1.0 &  -1.0 \\\\\n",
      "pt  &    NaN &   NaN &    NaN &   NaN &    NaN &   NaN &    1.0 &   1.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Output language identification results for en-fr (newline-cut-custom-truncate)}\n",
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "{} & \\multicolumn{2}{l}{0} & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{5} \\\\\n",
      "{} & \\multicolumn{2}{l}{ldiff} & \\multicolumn{2}{l}{ldiff} & \\multicolumn{2}{l}{ldiff} & \\multicolumn{2}{l}{ldiff} \\\\\n",
      "{} &  count &  mean &  count &  mean &  count &  mean &  count & mean \\\\\n",
      "\\midrule\n",
      "cs &    1.0 & 408.0 &    NaN &   NaN &    NaN &   NaN &    NaN &  NaN \\\\\n",
      "de &    1.0 &   3.0 &    2.0 & 146.0 &    2.0 & -12.5 &    1.0 &  2.0 \\\\\n",
      "en &  181.0 &  16.0 &   32.0 &  57.0 &   10.0 &  73.8 &    8.0 & 92.2 \\\\\n",
      "es &    1.0 &  12.0 &    3.0 &  89.3 &    NaN &   NaN &    NaN &  NaN \\\\\n",
      "fr & 2814.0 &   7.9 & 2959.0 &   2.1 & 2989.0 &   1.5 & 2992.0 &  1.6 \\\\\n",
      "ht &    1.0 &  57.0 &    1.0 &  89.0 &    NaN &   NaN &    NaN &  NaN \\\\\n",
      "it &    2.0 &   4.5 &    3.0 &  13.3 &    NaN &   NaN &    NaN &  NaN \\\\\n",
      "nl &    1.0 & 131.0 &    NaN &   NaN &    NaN &   NaN &    NaN &  NaN \\\\\n",
      "pt &    1.0 & 146.0 &    NaN &   NaN &    NaN &   NaN &    NaN &  NaN \\\\\n",
      "ms &    NaN &   NaN &    1.0 &  28.0 &    NaN &   NaN &    NaN &  NaN \\\\\n",
      "ru &    NaN &   NaN &    1.0 &  16.0 &    NaN &   NaN &    NaN &  NaN \\\\\n",
      "zh &    NaN &   NaN &    1.0 &  10.0 &    NaN &   NaN &    NaN &  NaN \\\\\n",
      "ca &    NaN &   NaN &    NaN &   NaN &    1.0 & 198.0 &    1.0 & 18.0 \\\\\n",
      "uk &    NaN &   NaN &    NaN &   NaN &    1.0 &   3.0 &    1.0 &  3.0 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{Output language identification results for fr-en (newline-cut-custom-truncate)}\n",
      "\\begin{tabular}{lrrrrrrrr}\n",
      "\\toprule\n",
      "{} & \\multicolumn{2}{l}{0} & \\multicolumn{2}{l}{1} & \\multicolumn{2}{l}{2} & \\multicolumn{2}{l}{5} \\\\\n",
      "{} & \\multicolumn{2}{l}{ldiff} & \\multicolumn{2}{l}{ldiff} & \\multicolumn{2}{l}{ldiff} & \\multicolumn{2}{l}{ldiff} \\\\\n",
      "{} &  count &  mean &  count & mean &  count & mean &  count & mean \\\\\n",
      "\\midrule\n",
      "en & 2954.0 &   1.0 & 2979.0 &  0.8 & 2988.0 &  1.0 & 2987.0 &  1.3 \\\\\n",
      "fr &   47.0 & -23.4 &   22.0 & -1.4 &   13.0 &  1.3 &   13.0 & -2.2 \\\\\n",
      "it &    1.0 &   3.0 &    NaN &  NaN &    2.0 &  6.0 &    3.0 &  5.3 \\\\\n",
      "tr &    1.0 &  -1.0 &    1.0 & -1.0 &    NaN &  NaN &    NaN &  NaN \\\\\n",
      "es &    NaN &   NaN &    1.0 &  1.0 &    NaN &  NaN &    NaN &  NaN \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fasttext\n",
    "lid_model = fasttext.load_model('/Users/yvon/CNRS-Cloud/Projects/2021-BigScience/Analysis/Outputs/lid.176.ftz')\n",
    "\n",
    "def detector(text):\n",
    "    text = str(text)\n",
    "    # return empty string if there is no tweet\n",
    "    if text.isspace():\n",
    "        return \"\"\n",
    "    else:\n",
    "        # get first item of the prediction tuple, then split by \"__label__\" and return only language code\n",
    "        text = re.sub(\"\\n\", \" \", text)\n",
    "        return lid_model.predict(text)[0][0].split(\"__label__\")[1]\n",
    "\n",
    "def perlang_analysis(model, postproc):\n",
    "    mask = pd.array(allres['prompt'] == \"xglm\", dtype=\"boolean\") & \\\n",
    "    pd.array(allres['fewshot'] < 10, dtype=\"boolean\") & \\\n",
    "    pd.array(allres['postproc'] == postproc) &\\\n",
    "    pd.array(allres['model'] == model) &\\\n",
    "    pd.array(allres['prptype'] == \"source+target\")\n",
    "    filtered = allres[mask]\n",
    "    selected = filtered.loc[:, ['task', 'fewshot', 'filename', 'src', 'trg']]\n",
    "    # tasks = selected.loc[:,'task'].drop_duplicates().to_list()\n",
    "    # print(tasks)\n",
    "    selected['path'] = rootdir + selected['task'] + \"/\" + selected['fewshot'].astype(str) + \"-shot/tsv/\" + selected['filename']\n",
    "    selected['langpair'] = selected['src'] + \"-\" + selected['trg']\n",
    "    pairs =  selected.loc[:,'langpair'].drop_duplicates().to_list()\n",
    "    print(pairs)\n",
    "    \n",
    "    for pair in pairs:\n",
    "        mask = pd.array(selected['langpair'] == pair)\n",
    "        filtered = selected[mask]\n",
    "        \n",
    "        L = filtered.loc[:,'path'].to_list()\n",
    "        S = filtered.loc[:,'fewshot'].to_list()\n",
    "        L.sort()\n",
    "        S.sort()\n",
    "        allstats = []\n",
    "        \n",
    "        for wmtoutput in L:\n",
    "    \n",
    "            # print('\\n**** wmt output:', wmtoutput, '\\n')\n",
    "            # Make sure quoting = 3 - this matters to avoid errors\n",
    "            translations = pd.read_csv(wmtoutput, sep='\\t', quoting=3, engine = \"python\", names = ['ctx','ref','hyp'], dtype={0:str, 1:str, 2:str})\n",
    "            # print(translations.shape)\n",
    "            # print(translations.head())\n",
    "    \n",
    "            translations['empty'] = translations.apply(lambda row: len(str(row.hyp)) == 0, axis=1)\n",
    "            translations['ldiff'] = translations.apply(lambda row: len(str(row.ref)) - len(str(row.hyp)),axis=1)\n",
    "            translations['lang'] = translations.apply(lambda row: detector(row.hyp), axis=1)\n",
    "            bylang = translations.groupby('lang').describe()\n",
    "            empty = translations.groupby('empty').describe()\n",
    "             \n",
    "            allstats.append(bylang)\n",
    "            # print(empty)\n",
    "        alltab = pd.concat(allstats, axis = 1, keys = S)\n",
    "        \n",
    "        if (alltab.shape[0] > 0):\n",
    "            cols = [(key, 'ldiff', heading) for (key, heading) in [(k, h) for k in S for h in ['count','mean']]]\n",
    "            print(alltab.to_latex(\n",
    "                    # header = ['N', 'Delta','N', 'Delta','N', 'Delta','N', 'Delta'],\n",
    "                    columns = cols,\n",
    "                    multicolumn = True,\n",
    "                    float_format = \"%.1f\",\n",
    "                    caption = \"Output language identification results for \" + pair + \" (\" + postprocs + \")\"\n",
    "                    ))\n",
    "        \n",
    "        \n",
    "models = \"bloom\"\n",
    "postprocs = \"newline-cut-custom-truncate\"\n",
    "perlang_analysis(models, postprocs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687b3e12",
   "metadata": {},
   "source": [
    "### Third table, Number of shots ###\n",
    "bloom xglm prompt, all directions and pairs, show the effect of increasing the fewshot = 0-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "4dddaf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    model  fewshot                     postproc  spBLEU src trg\n",
      "16  bloom        0  newline-cut-custom-truncate   32.25  en  fr\n",
      "20  bloom        1  newline-cut-custom-truncate   36.29  en  fr\n",
      "28  bloom        2  newline-cut-custom-truncate   37.62  en  fr\n",
      "24  bloom        5  newline-cut-custom-truncate   37.88  en  fr\n",
      "17  bloom        0                         none   14.91  en  fr\n",
      "21  bloom        1                         none   27.83  en  fr\n",
      "29  bloom        2                         none   35.09  en  fr\n",
      "25  bloom        5                         none   37.89  en  fr\n",
      "0   bloom        0  newline-cut-custom-truncate   12.10  en  hi\n",
      "4   bloom        1  newline-cut-custom-truncate   15.73  en  hi\n",
      "12  bloom        2  newline-cut-custom-truncate   15.78  en  hi\n",
      "8   bloom        5  newline-cut-custom-truncate   16.46  en  hi\n",
      "1   bloom        0                         none    6.80  en  hi\n",
      "5   bloom        1                         none   13.62  en  hi\n",
      "13  bloom        2                         none   15.84  en  hi\n",
      "9   bloom        5                         none   16.50  en  hi\n",
      "18  bloom        0  newline-cut-custom-truncate   37.16  fr  en\n",
      "22  bloom        1  newline-cut-custom-truncate   38.18  fr  en\n",
      "30  bloom        2  newline-cut-custom-truncate   38.31  fr  en\n",
      "26  bloom        5  newline-cut-custom-truncate   38.98  fr  en\n",
      "19  bloom        0                         none   15.52  fr  en\n",
      "23  bloom        1                         none   34.61  fr  en\n",
      "31  bloom        2                         none   37.19  fr  en\n",
      "27  bloom        5                         none   38.94  fr  en\n",
      "2   bloom        0  newline-cut-custom-truncate   24.29  hi  en\n",
      "6   bloom        1  newline-cut-custom-truncate   25.04  hi  en\n",
      "14  bloom        2  newline-cut-custom-truncate   25.65  hi  en\n",
      "10  bloom        5  newline-cut-custom-truncate   26.24  hi  en\n",
      "3   bloom        0                         none   12.05  hi  en\n",
      "7   bloom        1                         none   25.04  hi  en\n",
      "15  bloom        2                         none   25.69  hi  en\n",
      "11  bloom        5                         none   26.36  hi  en\n"
     ]
    }
   ],
   "source": [
    "def pershot_analysis():\n",
    "    mask = pd.array(allres['prompt'] == \"xglm\", dtype=\"boolean\") & \\\n",
    "    pd.array(allres['fewshot'] < 6 , dtype=\"boolean\") & \\\n",
    "    pd.array(allres['postproc'] != \"newline-cut\") &\\\n",
    "    pd.array(allres['model'] == \"bloom\", dtype=\"boolean\") &\\\n",
    "    pd.array(allres['prptype'] == \"source+target\")\n",
    "    filtered = allres[mask]\n",
    "    selected = filtered.loc[:, ['model', 'fewshot', 'postproc', 'spBLEU', 'src', 'trg',]]\n",
    "    selected.drop_duplicates(keep='first', inplace=True, ignore_index=True)\n",
    "    print(selected.sort_values(by=['model', 'src', 'trg', 'postproc', 'fewshot'], axis=0))\n",
    "\n",
    "pershot_analysis()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc7f5c8",
   "metadata": {},
   "source": [
    "### Show variability by prompt ### \n",
    "This analysis is run for all models, with a restricted list of prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "f32b46ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**** Source / target hi en **** postproc none  ****\n",
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{BLEU scores by model for hi-en (none)}\n",
      "\\begin{tabular}{lrrrrrrrrrrrr}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{l}{en-hi (0-shot)} & \\multicolumn{3}{l}{hi-en (0-shot)} & \\multicolumn{3}{l}{en-hi (1-shot)} & \\multicolumn{3}{l}{hi-en (1-shot)} \\\\\n",
      "{} & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} \\\\\n",
      "{} &           mean &  min &  max &           mean &  min &   max &           mean &  min &   max &           mean &  min &   max \\\\\n",
      "model      &                &      &      &                &      &       &                &      &       &                &      &       \\\\\n",
      "\\midrule\n",
      "bloom      &           2.05 & 0.26 & 6.80 &           8.59 & 0.66 & 13.04 &          12.88 & 6.51 & 14.55 &          20.58 & 9.98 & 25.80 \\\\\n",
      "bloom-1b1  &           0.07 & 0.02 & 0.11 &           1.40 & 0.00 &  4.54 &           1.44 & 0.05 &  3.08 &           5.18 & 0.00 &  8.15 \\\\\n",
      "bloom-3b   &           0.22 & 0.03 & 0.54 &           3.86 & 0.02 &  6.96 &           4.89 & 0.21 &  7.25 &           9.76 & 0.08 & 13.86 \\\\\n",
      "bloom-560m &           0.06 & 0.03 & 0.08 &           0.79 & 0.01 &  1.74 &           0.21 & 0.02 &  0.34 &           1.70 & 0.06 &  2.84 \\\\\n",
      "bloom-7b1  &           0.95 & 0.05 & 2.96 &           5.67 & 0.29 &  9.50 &           5.92 & 0.30 & 10.38 &          13.03 & 1.03 & 17.53 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "**** Source / target fr en **** postproc none  ****\n",
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{BLEU scores by model for fr-en (none)}\n",
      "\\begin{tabular}{lrrrrrrrrrrrr}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{l}{en-fr (0-shot)} & \\multicolumn{3}{l}{fr-en (0-shot)} & \\multicolumn{3}{l}{en-fr (1-shot)} & \\multicolumn{3}{l}{fr-en (1-shot)} \\\\\n",
      "{} & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} \\\\\n",
      "{} &           mean &  min &   max &           mean &   min &   max &           mean &   min &   max &           mean &   min &   max \\\\\n",
      "model      &                &      &       &                &       &       &                &       &       &                &       &       \\\\\n",
      "\\midrule\n",
      "bloom      &          11.17 & 2.97 & 21.96 &          15.38 & 10.33 & 26.79 &          32.60 & 27.83 & 36.39 &          34.91 & 33.14 & 36.56 \\\\\n",
      "bloom-1b1  &           1.66 & 0.52 &  3.89 &           7.10 &  0.73 & 11.44 &          10.07 &  6.31 & 13.24 &          16.12 & 12.17 & 19.89 \\\\\n",
      "bloom-3b   &           3.60 & 1.21 &  9.60 &          10.61 &  2.84 & 19.34 &          21.62 & 16.69 & 26.83 &          25.67 & 18.64 & 29.56 \\\\\n",
      "bloom-560m &           0.57 & 0.39 &  0.86 &           3.66 &  1.42 &  5.43 &           3.62 &  2.16 &  4.41 &           8.63 &  5.83 & 12.14 \\\\\n",
      "bloom-7b1  &           6.51 & 1.52 & 12.12 &          12.82 &  4.77 & 25.10 &          25.92 & 20.78 & 29.94 &          29.12 & 25.44 & 32.51 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "**** Source / target hi en **** postproc newline-cut-custom-truncate  ****\n",
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{BLEU scores by model for hi-en (newline-cut-custom-truncate)}\n",
      "\\begin{tabular}{lrrrrrrrrrrrr}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{l}{en-hi (0-shot)} & \\multicolumn{3}{l}{hi-en (0-shot)} & \\multicolumn{3}{l}{en-hi (1-shot)} & \\multicolumn{3}{l}{hi-en (1-shot)} \\\\\n",
      "{} & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} \\\\\n",
      "{} &           mean &  min &   max &           mean &  min &   max &           mean &  min &   max &           mean &   min &   max \\\\\n",
      "model      &                &      &       &                &      &       &                &      &       &                &       &       \\\\\n",
      "\\midrule\n",
      "bloom      &           3.46 & 0.05 & 12.10 &          14.92 & 0.03 & 25.40 &          13.38 & 7.59 & 15.73 &          20.74 & 11.44 & 25.75 \\\\\n",
      "bloom-1b1  &           0.09 & 0.03 &  0.13 &           2.02 & 0.00 &  6.87 &           1.32 & 0.05 &  2.83 &           5.56 &  0.00 &  8.35 \\\\\n",
      "bloom-3b   &           0.38 & 0.02 &  0.99 &           6.11 & 0.01 & 11.19 &           4.83 & 0.22 &  7.45 &          10.03 &  0.07 & 13.97 \\\\\n",
      "bloom-560m &           0.07 & 0.04 &  0.10 &           0.97 & 0.00 &  2.39 &           0.18 & 0.01 &  0.32 &           1.56 &  0.01 &  2.72 \\\\\n",
      "bloom-7b1  &           1.72 & 0.02 &  6.58 &           8.79 & 0.03 & 15.29 &           6.05 & 0.33 & 10.37 &          13.08 &  0.99 & 17.52 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "**** Source / target fr en **** postproc newline-cut-custom-truncate  ****\n",
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{BLEU scores by model for fr-en (newline-cut-custom-truncate)}\n",
      "\\begin{tabular}{lrrrrrrrrrrrr}\n",
      "\\toprule\n",
      "{} & \\multicolumn{3}{l}{en-fr (0-shot)} & \\multicolumn{3}{l}{fr-en (0-shot)} & \\multicolumn{3}{l}{en-fr (1-shot)} & \\multicolumn{3}{l}{fr-en (1-shot)} \\\\\n",
      "{} & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} \\\\\n",
      "{} &           mean &  min &   max &           mean &   min &   max &           mean &   min &   max &           mean &   min &   max \\\\\n",
      "model      &                &      &       &                &       &       &                &       &       &                &       &       \\\\\n",
      "\\midrule\n",
      "bloom      &          17.45 & 4.60 & 32.25 &          26.87 & 16.86 & 37.16 &          35.64 & 33.08 & 37.12 &          36.94 & 35.72 & 38.18 \\\\\n",
      "bloom-1b1  &           2.82 & 0.69 &  7.92 &          11.67 &  1.29 & 20.42 &          11.56 &  7.32 & 17.22 &          17.93 & 13.43 & 21.68 \\\\\n",
      "bloom-3b   &           6.25 & 1.89 & 19.24 &          17.92 &  5.08 & 28.85 &          23.81 & 19.26 & 26.98 &          27.18 & 22.02 & 29.68 \\\\\n",
      "bloom-560m &           0.80 & 0.55 &  1.33 &           5.16 &  2.24 &  8.33 &           4.36 &  3.03 &  6.85 &           9.91 &  7.25 & 12.50 \\\\\n",
      "bloom-7b1  &          10.51 & 2.08 & 25.15 &          21.81 &  7.21 & 33.28 &          28.07 & 24.73 & 30.39 &          30.77 & 27.97 & 32.78 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0r/l7kgc3mn5vl8vkcw3kjk41gh0000gp/T/ipykernel_14651/1649084562.py:69: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(alltab.to_latex(\n",
      "/var/folders/0r/l7kgc3mn5vl8vkcw3kjk41gh0000gp/T/ipykernel_14651/1649084562.py:69: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(alltab.to_latex(\n",
      "/var/folders/0r/l7kgc3mn5vl8vkcw3kjk41gh0000gp/T/ipykernel_14651/1649084562.py:69: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(alltab.to_latex(\n",
      "/var/folders/0r/l7kgc3mn5vl8vkcw3kjk41gh0000gp/T/ipykernel_14651/1649084562.py:69: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(alltab.to_latex(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def permodel_analysis(allres, metric=\"BLEU\", metriclab = \"BLEU\"):\n",
    "    modelList = [\n",
    "    \"bloom-560m\", \n",
    "    \"bloom\", \n",
    "    \"bloom-1b1\", \n",
    "#    \"bloom-1b7\", \n",
    "    \"bloom-3b\", \n",
    "    \"bloom-7b1\"\n",
    "    ]\n",
    "    templateList = [\n",
    "    \"a_good_translation-en-fr-source+target\", \"a_good_translation-en-fr-target\", \\\n",
    "    \"a_good_translation-fr-en-source+target\", \"a_good_translation-fr-en-target\", \\\n",
    "    \"gpt-3-en-fr-target\", \"gpt-3-fr-en-target\", \\\n",
    "    \"translate_as-en-fr-target\", \"translate_as-fr-en-target\", \\\n",
    "    \"version-en-fr-target\", \"version-fr-en-target\", \\\n",
    "    \"xglm-en-fr-source+target\", \"xglm-en-fr-target\", \\\n",
    "    \"xglm-fr-en-source+target\", \"xglm-fr-en-target\",\n",
    "    \"a_good_translation-en-hi-source+target\", \"a_good_translation-en-hi-target\", \\\n",
    "    \"a_good_translation-en-hi-target\", \"a_good_translation-hi-en-target\", \\\n",
    "    \"gpt-3-en-hi-target\", \"gpt-3-hi-en-target\", \\\n",
    "    \"translate_as-en-hi-target\", \"translate_as-hi-en-target\", \\\n",
    "    \"version-en-hi-target\", \"version-hi-en-target\", \\\n",
    "    \"xglm-en-hi-source+target\", \"xglm-en-hi-target\", \\\n",
    "    \"xglm-hi-en-source+target\", \"xglm-hi-en-target\",\n",
    "    ] \n",
    "\n",
    "    mask = pd.array(allres['fewshot'] < 2 , dtype=\"boolean\") & \\\n",
    "    pd.array(allres['postproc'] != \"newline-cut\") & \\\n",
    "    pd.array(allres['model'].isin(modelList)) & \\\n",
    "    pd.array(allres['template'].isin(templateList))\n",
    "\n",
    "    filtered = allres[mask]\n",
    "    selected = filtered.loc[:, ['model', 'fewshot', 'postproc', metric, 'src', 'trg', 'prompt', 'prptype']]\n",
    "    selected.drop_duplicates(keep='first', inplace=True, ignore_index=True)\n",
    "    alltab = []\n",
    "\n",
    "    hien = [('en', 'hi'), ('hi', 'en')]\n",
    "    fren = [('en', 'fr'), ('fr', 'en')]\n",
    "    for postproc in [\"none\", \"newline-cut-custom-truncate\"]:\n",
    "        for langpairs in hien, fren:\n",
    "            alllst = []\n",
    "            keylst = []\n",
    "            for shot in [0,1]:\n",
    "                for (src, trg) in langpairs:    \n",
    "                # print(sel.head())\n",
    "                    mask = pd.array(selected['src'] == src, dtype=\"boolean\") & pd.array(selected['trg'] == trg, dtype=\"boolean\")\n",
    "                    sel = selected[mask]\n",
    "                    sel = sel[sel['fewshot'] == shot] # .loc[:,['model_name','score']]\n",
    "                    sel = sel[sel['postproc'] == postproc] # .loc[:,['model_name','score']]\n",
    "                    filt = sel.loc[:,['model','BLEU']]\n",
    "                    # print(sel.head())\n",
    "                    # print(\"\\n**** Source / target\", src, trg, \" **** shots\", shot, \"**** postproc\", postproc, \"****\")\n",
    "                    tab = filt.groupby(['model']).describe(percentiles=[])\n",
    "                    alllst.append(tab)\n",
    "                    keylst.append(src + \"-\" + trg + \" (\" + str(shot) + \"-shot)\")\n",
    "                    # \n",
    "                    if (tab.shape[0] > 10):\n",
    "                        print(tab.to_latex(\n",
    "                        #header = ['avg', 'min' , 'max'],\n",
    "                        columns = [(metric, 'mean'), (metric, 'min'), (metric, 'max')],\n",
    "                        float_format = \"%.2f\",\n",
    "                        caption = metriclab + \" by model for \" + src + \"-\" + trg + \" (\" + str(shot) + \" shot, \" + postproc + \")\"\n",
    "                        ))\n",
    "            alltab = pd.concat(alllst, axis = 1, keys = keylst)\n",
    "            # print(alltab)\n",
    "            print(\"\\n**** Source / target\", src, trg, \"**** postproc\", postproc, \" ****\")\n",
    "            if (alltab.shape[0] > 0):\n",
    "                cols = [(key, metric, heading) for (key, heading) in [(k, h) for k in keylst for h in ['mean','min', 'max']]]\n",
    "                print(alltab.to_latex(\n",
    "                        #header = ['avg', 'min' , 'max'],\n",
    "                        columns = cols,\n",
    "                        multicolumn = True,\n",
    "                        float_format = \"%.2f\",\n",
    "                        caption = metriclab + \" by model for \" + src + \"-\" + trg + \" (\" + postproc + \")\"\n",
    "                        ))\n",
    "    return(1)\n",
    "                      \n",
    "permodel_analysis(allres, metric=\"BLEU\", metriclab = \"BLEU scores\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "b4bae46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**** Source / target hi en **** postproc none  ****\n",
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{BLEU scores per prompt for hi-en (none)}\n",
      "\\begin{tabular}{llrrrrrrrrrrrr}\n",
      "\\toprule\n",
      "     &        & \\multicolumn{3}{l}{en-hi (0-shot)} & \\multicolumn{3}{l}{hi-en (0-shot)} & \\multicolumn{3}{l}{en-hi (1-shot)} & \\multicolumn{3}{l}{hi-en (1-shot)} \\\\\n",
      "     &        & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} \\\\\n",
      "     &        &           mean &  min &  max &           mean &  min &   max &           mean &  min &   max &           mean &  min &   max \\\\\n",
      "prompt & prptype &                &      &      &                &      &       &                &      &       &                &      &       \\\\\n",
      "\\midrule\n",
      "a\\_good\\_translation & source+target &           0.72 & 0.07 & 1.90 &           4.84 & 0.88 & 10.19 &           5.80 & 0.34 & 14.49 &          13.06 & 2.78 & 24.60 \\\\\n",
      "     & target &           0.22 & 0.06 & 0.77 &           6.29 & 1.13 & 13.04 &           5.54 & 0.33 & 14.14 &          13.23 & 2.84 & 24.84 \\\\\n",
      "gpt3 & target &           0.09 & 0.03 & 0.26 &           0.20 & 0.00 &  0.66 &           1.42 & 0.02 &  6.51 &           2.23 & 0.00 &  9.98 \\\\\n",
      "version & target &           0.74 & 0.08 & 1.96 &           6.82 & 1.74 & 11.48 &           5.58 & 0.17 & 13.95 &          13.26 & 2.42 & 25.80 \\\\\n",
      "xglm & source+target &           2.05 & 0.06 & 6.80 &           4.40 & 0.63 & 12.05 &           6.93 & 0.32 & 13.62 &          11.94 & 1.66 & 25.04 \\\\\n",
      "     & target &           0.19 & 0.02 & 0.63 &           1.57 & 0.22 &  4.10 &           5.13 & 0.08 & 14.55 &           6.58 & 0.47 & 13.22 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "**** Source / target fr en **** postproc none  ****\n",
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{BLEU scores per prompt for fr-en (none)}\n",
      "\\begin{tabular}{llrrrrrrrrrrrr}\n",
      "\\toprule\n",
      "     &        & \\multicolumn{3}{l}{en-fr (0-shot)} & \\multicolumn{3}{l}{fr-en (0-shot)} & \\multicolumn{3}{l}{en-fr (1-shot)} & \\multicolumn{3}{l}{fr-en (1-shot)} \\\\\n",
      "     &        & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} \\\\\n",
      "     &        &           mean &  min &   max &           mean &  min &   max &           mean &  min &   max &           mean &   min &   max \\\\\n",
      "prompt & prptype &                &      &       &                &      &       &                &      &       &                &       &       \\\\\n",
      "\\midrule\n",
      "a\\_good\\_translation & source+target &           6.66 & 0.57 & 15.38 &          10.96 & 5.43 & 14.15 &          18.68 & 4.12 & 36.39 &          25.76 & 11.64 & 36.56 \\\\\n",
      "     & target &           3.15 & 0.40 & 10.14 &          12.05 & 5.11 & 16.81 &          20.32 & 3.23 & 35.47 &          25.86 & 12.14 & 36.24 \\\\\n",
      "gpt3 & target &           2.48 & 0.46 &  7.90 &           4.50 & 0.73 & 12.73 &          16.64 & 2.16 & 32.55 &          19.28 &  5.83 & 33.14 \\\\\n",
      "translate\\_as & target &           3.30 & 0.39 &  5.04 &           6.85 & 2.15 & 11.35 &          17.15 & 3.23 & 32.74 &          21.63 &  7.60 & 35.12 \\\\\n",
      "version & target &           7.48 & 0.58 & 21.96 &          17.06 & 3.87 & 26.79 &          21.38 & 4.33 & 34.22 &          24.88 &  7.85 & 35.42 \\\\\n",
      "xglm & source+target &           8.28 & 0.86 & 14.91 &          11.76 & 5.01 & 15.52 &          17.52 & 3.34 & 27.83 &          22.09 &  7.85 & 34.61 \\\\\n",
      "     & target &           1.57 & 0.70 &  2.97 &           6.23 & 2.65 & 10.33 &          16.67 & 4.41 & 28.99 &          20.73 &  7.48 & 33.30 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "**** Source / target hi en **** postproc newline-cut-custom-truncate  ****\n",
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{BLEU scores per prompt for hi-en (newline-cut-custom-truncate)}\n",
      "\\begin{tabular}{llrrrrrrrrrrrr}\n",
      "\\toprule\n",
      "     &        & \\multicolumn{3}{l}{en-hi (0-shot)} & \\multicolumn{3}{l}{hi-en (0-shot)} & \\multicolumn{3}{l}{en-hi (1-shot)} & \\multicolumn{3}{l}{hi-en (1-shot)} \\\\\n",
      "     &        & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} \\\\\n",
      "     &        &           mean &  min &   max &           mean &  min &   max &           mean &  min &   max &           mean &  min &   max \\\\\n",
      "prompt & prptype &                &      &       &                &      &       &                &      &       &                &      &       \\\\\n",
      "\\midrule\n",
      "a\\_good\\_translation & source+target &           1.18 & 0.08 &  3.29 &           6.25 & 1.02 & 12.65 &           5.77 & 0.32 & 14.46 &          13.00 & 2.61 & 24.44 \\\\\n",
      "     & target &           0.36 & 0.07 &  1.34 &          10.83 & 1.08 & 25.40 &           5.50 & 0.31 & 14.11 &          13.21 & 2.72 & 24.74 \\\\\n",
      "gpt3 & target &           0.04 & 0.02 &  0.05 &           0.01 & 0.00 &  0.03 &           1.64 & 0.03 &  7.59 &           2.50 & 0.00 & 11.44 \\\\\n",
      "version & target &           1.05 & 0.10 &  2.98 &          11.34 & 2.39 & 21.39 &           5.56 & 0.15 & 13.90 &          13.52 & 2.68 & 25.75 \\\\\n",
      "xglm & source+target &           3.94 & 0.07 & 12.10 &           8.80 & 0.86 & 24.29 &           7.32 & 0.23 & 15.73 &          12.40 & 1.21 & 25.04 \\\\\n",
      "     & target &           0.29 & 0.02 &  1.03 &           2.14 & 0.27 &  5.75 &           5.11 & 0.01 & 14.46 &           6.54 & 0.15 & 13.01 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "**** Source / target fr en **** postproc newline-cut-custom-truncate  ****\n",
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{BLEU scores per prompt for fr-en (newline-cut-custom-truncate)}\n",
      "\\begin{tabular}{llrrrrrrrrrrrr}\n",
      "\\toprule\n",
      "     &        & \\multicolumn{3}{l}{en-fr (0-shot)} & \\multicolumn{3}{l}{fr-en (0-shot)} & \\multicolumn{3}{l}{en-fr (1-shot)} & \\multicolumn{3}{l}{fr-en (1-shot)} \\\\\n",
      "     &        & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} & \\multicolumn{3}{l}{spBLEU} \\\\\n",
      "     &        &           mean &  min &   max &           mean &  min &   max &           mean &  min &   max &           mean &   min &   max \\\\\n",
      "prompt & prptype &                &      &       &                &      &       &                &      &       &                &       &       \\\\\n",
      "\\midrule\n",
      "a\\_good\\_translation & source+target &           8.54 & 0.69 & 17.04 &          16.42 & 7.49 & 22.19 &          19.08 & 4.32 & 37.12 &          25.99 & 11.96 & 36.96 \\\\\n",
      "     & target &           4.62 & 0.55 & 13.89 &          21.72 & 6.60 & 35.20 &          20.88 & 3.37 & 36.81 &          26.31 & 12.50 & 36.90 \\\\\n",
      "gpt3 & target &           4.03 & 0.67 & 13.96 &           8.31 & 1.29 & 25.71 &          18.71 & 3.03 & 36.42 &          21.57 &  7.25 & 37.18 \\\\\n",
      "translate\\_as & target &           6.45 & 0.60 & 10.12 &          11.54 & 2.29 & 20.35 &          18.07 & 3.55 & 33.08 &          22.88 &  8.15 & 35.72 \\\\\n",
      "version & target &           9.66 & 0.68 & 30.31 &          22.20 & 4.71 & 35.17 &          21.88 & 4.37 & 36.71 &          25.31 &  7.99 & 37.24 \\\\\n",
      "xglm & source+target &          17.18 & 1.33 & 32.25 &          25.61 & 8.33 & 37.16 &          23.18 & 5.02 & 36.29 &          26.65 & 11.10 & 38.18 \\\\\n",
      "     & target &           2.50 & 1.08 &  4.60 &          11.00 & 4.45 & 17.61 &          20.08 & 6.85 & 33.08 &          23.10 & 10.45 & 36.42 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/0r/l7kgc3mn5vl8vkcw3kjk41gh0000gp/T/ipykernel_14651/870374572.py:68: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(alltab.to_latex(\n",
      "/var/folders/0r/l7kgc3mn5vl8vkcw3kjk41gh0000gp/T/ipykernel_14651/870374572.py:68: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(alltab.to_latex(\n",
      "/var/folders/0r/l7kgc3mn5vl8vkcw3kjk41gh0000gp/T/ipykernel_14651/870374572.py:68: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(alltab.to_latex(\n",
      "/var/folders/0r/l7kgc3mn5vl8vkcw3kjk41gh0000gp/T/ipykernel_14651/870374572.py:68: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(alltab.to_latex(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Like previous function, could be improved by dropping one level of indexing\n",
    "def perprompt_analysis(allres, metric=\"BLEU\", metriclab = \"BLEU\"):\n",
    "    modelList = [\n",
    "    \"bloom-560m\", \n",
    "    \"bloom\", \n",
    "    \"bloom-1b1\", \n",
    "#    \"bloom-1b7\", \n",
    "    \"bloom-3b\", \n",
    "    \"bloom-7b1\"\n",
    "    ]\n",
    "    templateList = [\n",
    "    \"a_good_translation-en-fr-source+target\", \"a_good_translation-en-fr-target\", \\\n",
    "    \"a_good_translation-fr-en-source+target\", \"a_good_translation-fr-en-target\", \\\n",
    "    \"gpt-3-en-fr-target\", \"gpt-3-fr-en-target\", \\\n",
    "    \"translate_as-en-fr-target\", \"translate_as-fr-en-target\", \\\n",
    "    \"version-en-fr-target\", \"version-fr-en-target\", \\\n",
    "    \"xglm-en-fr-source+target\", \"xglm-en-fr-target\", \\\n",
    "    \"xglm-fr-en-source+target\", \"xglm-fr-en-target\",\n",
    "    \"a_good_translation-en-hi-source+target\", \"a_good_translation-en-hi-target\", \\\n",
    "    \"a_good_translation-hi-en-source+target\", \"a_good_translation-hi-en-target\", \\\n",
    "    \"gpt-3-en-hi-target\", \"gpt-3-hi-en-target\", \\\n",
    "    \"translate_as-en-hi-target\", \"translate_as-hi-en-target\", \\\n",
    "    \"version-en-hi-target\", \"version-hi-en-target\", \\\n",
    "    \"xglm-en-hi-source+target\", \"xglm-en-hi-target\", \\\n",
    "    \"xglm-hi-en-source+target\", \"xglm-hi-en-target\",\n",
    "    ] \n",
    "\n",
    "    mask = pd.array(allres['fewshot'] < 2 , dtype=\"boolean\") & \\\n",
    "    pd.array(allres['postproc'] != \"newline-cut\") & \\\n",
    "    pd.array(allres['model'].isin(modelList)) & \\\n",
    "    pd.array(allres['template'].isin(templateList))\n",
    "\n",
    "    filtered = allres[mask]\n",
    "    selected = filtered.loc[:, ['model', 'fewshot', 'postproc', 'BLEU', 'src', 'trg', 'prompt', 'prptype']]\n",
    "    selected.drop_duplicates(keep='first', inplace=True, ignore_index=True)\n",
    "\n",
    "    hien = [('en', 'hi'), ('hi', 'en')]\n",
    "    fren = [('en', 'fr'), ('fr', 'en')]\n",
    "    for postproc in [\"none\", \"newline-cut-custom-truncate\"]:\n",
    "        for langpairs in hien, fren:\n",
    "            alllst = []\n",
    "            keylst = []\n",
    "            for shot in [0,1]:\n",
    "                for (src, trg) in langpairs:    \n",
    "                # print(sel.head())\n",
    "                    mask = pd.array(selected['src'] == src, dtype=\"boolean\") & pd.array(selected['trg'] == trg, dtype=\"boolean\")\n",
    "                    sel = selected[mask]\n",
    "                    sel = sel[sel['fewshot'] == shot] # .loc[:,['model_name','score']]\n",
    "                    sel = sel[sel['postproc'] == postproc] # .loc[:,['model_name','score']]\n",
    "                    filt = sel.loc[:,['prompt', 'prptype', 'BLEU']]\n",
    "                    # print(sel.head())\n",
    "                    # print(\"\\n**** Source / target\", src, trg, \" **** shots\", shot, \"**** postproc\", postproc, \"****\")\n",
    "                    tab = filt.groupby(['prompt', 'prptype']).describe(percentiles=[])\n",
    "                    alllst.append(tab)\n",
    "                    keylst.append(src + \"-\" + trg + \" (\" + str(shot) + \"-shot)\")\n",
    "                    # print(tab)\n",
    "                    #print(tab.to_latex(\n",
    "                    # header = ['avg', 'min' , 'max'],\n",
    "                    #    columns = [(metric, 'mean'), (metric, 'min'), (metric, 'max')],\n",
    "                    #   float_format = \"%.2f\",\n",
    "                    #   caption = metriclab + \" by prompt for \" + src + \"-\" + trg + \" (\" + str(shot) + \" shot, \" + postproc + \")\"\n",
    "                    #))\n",
    "            alltab = pd.concat(alllst, axis = 1, keys = keylst)\n",
    "            # print(alltab)\n",
    "            print(\"\\n**** Source / target\", src, trg, \"**** postproc\", postproc, \" ****\")\n",
    "            if (alltab.shape[0] > 0):\n",
    "                cols = [(key, metric, heading) for (key, heading) in [(k, h) for k in keylst for h in ['mean','min', 'max']]]\n",
    "                print(alltab.to_latex(\n",
    "                        #header = ['avg', 'min' , 'max'],\n",
    "                        columns = cols,\n",
    "                        multicolumn = True,\n",
    "                        float_format = \"%.2f\",\n",
    "                        caption = metriclab + \" per prompt for \" + src + \"-\" + trg + \" (\" + postproc + \")\"\n",
    "                        ))\n",
    "    return(1)\n",
    "\n",
    "perprompt_analysis(allres, metric=\"BLEU\", metriclab = \"BLEU scores\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
